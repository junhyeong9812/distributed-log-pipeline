# Distributed Log Pipeline

> ë¶„ì‚°ì²˜ë¦¬ ì‹œìŠ¤í…œ(Kubernetes, Hadoop, Spark)ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ ì‹¤ìŠµ í”„ë¡œì íŠ¸

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### ëª©ì 
Kubernetes, Hadoop, Sparkë¥¼ í™œìš©í•œ ë¶„ì‚° ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ì§ì ‘ êµ¬ì¶•í•˜ê³  ìš´ì˜í•´ë³´ë©° ë¶„ì‚°ì²˜ë¦¬ ì‹œìŠ¤í…œì˜ í•µì‹¬ ê°œë…ì„ í•™ìŠµí•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
- ë°°ì¹˜ ê¸°ë°˜ ë¡œê·¸/ì´ë²¤íŠ¸ ë°ì´í„° ìë™ ìƒì„±
- ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ë° ë©”ì‹œì§€ í ì²˜ë¦¬
- ë¶„ì‚° ì €ì¥ì†Œ(HDFS)ì— ë°ì´í„° ì ì¬
- Sparkë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„/ë°°ì¹˜ ë°ì´í„° ë¶„ì„
- Grafana ê¸°ë°˜ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ì „ì²´ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         System Architecture                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚       â”‚            ë…¸íŠ¸ë¶ (Master)               â”‚
â”‚   Data          â”‚       â”‚                                         â”‚
â”‚   Generator     â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   Server        â”‚ â”€â”€â”€â”€â–¶ â”‚  â”‚   Java Backend (Spring Boot)      â”‚  â”‚
â”‚                 â”‚ HTTP  â”‚  â”‚   â€¢ REST API ìˆ˜ì§‘ ì„œë²„             â”‚  â”‚
â”‚  (Python)       â”‚       â”‚  â”‚   â€¢ Kafka Producer                â”‚  â”‚
â”‚  â€¢ FastAPI      â”‚       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â€¢ ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬ â”‚       â”‚                    â”‚                    â”‚
â”‚  â€¢ ë°ì´í„° ìƒì„±ê¸° â”‚       â”‚                    â–¼                    â”‚
â”‚                 â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”‚   Kubernetes Control Plane        â”‚  â”‚
                          â”‚  â”‚   â€¢ API Server                    â”‚  â”‚
                          â”‚  â”‚   â€¢ Scheduler                     â”‚  â”‚
                          â”‚  â”‚   â€¢ etcd                          â”‚  â”‚
                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â”‚                    â”‚                    â”‚
                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                          â”‚  â”‚   Kafka + Zookeeper               â”‚  â”‚
                          â”‚  â”‚   â€¢ ë©”ì‹œì§€ í                      â”‚  â”‚
                          â”‚  â”‚   â€¢ ì‹¤ì‹œê°„ ë°ì´í„° ë²„í¼ë§           â”‚  â”‚
                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â”‚                    â”‚                    â”‚
                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                          â”‚  â”‚   Spark Driver + Airflow          â”‚  â”‚
                          â”‚  â”‚   â€¢ ì‘ì—… ìŠ¤ì¼€ì¤„ë§                  â”‚  â”‚
                          â”‚  â”‚   â€¢ ë¶„ì„ Job ê´€ë¦¬                  â”‚  â”‚
                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â”‚                    â”‚                    â”‚
                          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                          â”‚  â”‚   Monitoring Stack                â”‚  â”‚
                          â”‚  â”‚   â€¢ Grafana (ì‹œê°í™”)              â”‚  â”‚
                          â”‚  â”‚   â€¢ Prometheus (ë©”íŠ¸ë¦­ ìˆ˜ì§‘)       â”‚  â”‚
                          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚                                       â”‚
                          â–¼                                       â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   ë¦¬ëˆ…ìŠ¤ PC - A      â”‚             â”‚   ë¦¬ëˆ…ìŠ¤ PC - B      â”‚
               â”‚   (Worker Node 1)   â”‚             â”‚   (Worker Node 2)   â”‚
               â”‚                     â”‚             â”‚                     â”‚
               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
               â”‚ â”‚ K8s Worker      â”‚ â”‚             â”‚ â”‚ K8s Worker      â”‚ â”‚
               â”‚ â”‚ (kubelet)       â”‚ â”‚             â”‚ â”‚ (kubelet)       â”‚ â”‚
               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
               â”‚                     â”‚             â”‚                     â”‚
               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
               â”‚ â”‚ HDFS DataNode   â”‚ â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ â”‚ HDFS DataNode   â”‚ â”‚
               â”‚ â”‚ (ë°ì´í„° ì €ì¥)    â”‚ â”‚  Replicationâ”‚ â”‚ (ë°ì´í„° ì €ì¥)    â”‚ â”‚
               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
               â”‚                     â”‚             â”‚                     â”‚
               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
               â”‚ â”‚ Spark Executor  â”‚ â”‚             â”‚ â”‚ Spark Executor  â”‚ â”‚
               â”‚ â”‚ (ë°ì´í„° ì²˜ë¦¬)    â”‚ â”‚             â”‚ â”‚ (ë°ì´í„° ì²˜ë¦¬)    â”‚ â”‚
               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë°ì´í„° í”Œë¡œìš°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Data Flow                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. ë°ì´í„° ìƒì„± (Python Generator)
   â”‚
   â”‚  ë°°ì¹˜ ìŠ¤ì¼€ì¤„ (ë§¤ Nì´ˆ/ë¶„ë§ˆë‹¤)
   â”‚  â€¢ ì‹œìŠ¤í…œ ë¡œê·¸ ìƒì„±
   â”‚  â€¢ ì‚¬ìš©ì í™œë™ ì´ë²¤íŠ¸ ìƒì„±
   â–¼
2. ë°ì´í„° ìˆ˜ì§‘ (Java Spring Boot)
   â”‚
   â”‚  REST APIë¡œ ìˆ˜ì‹ 
   â”‚  â€¢ ë°ì´í„° ê²€ì¦
   â”‚  â€¢ Kafkaë¡œ ë°œí–‰
   â–¼
3. ë©”ì‹œì§€ í (Kafka)
   â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                      â”‚                      â”‚
   â–¼                      â–¼                      â–¼
4a. ì‹¤ì‹œê°„ ì²˜ë¦¬       4b. ë°°ì¹˜ ì €ì¥          4c. HDFS ì ì¬
    (Spark Streaming)     (Kafka â†’ HDFS)         (ì›ë³¸ ë³´ê´€)
    â”‚                      â”‚                      â”‚
    â”‚ â€¢ 5ì´ˆ ìœˆë„ìš° ì§‘ê³„     â”‚ â€¢ ì‹œê°„ë³„ íŒŒí‹°ì…˜      â”‚ â€¢ ì¥ê¸° ë³´ê´€
    â”‚ â€¢ ì´ìƒ íƒì§€          â”‚ â€¢ ì••ì¶• ì €ì¥          â”‚ â€¢ ì¬ì²˜ë¦¬ìš©
    â–¼                      â–¼                      â–¼
5. ê²°ê³¼ ì €ì¥
   â”‚
   â”œâ”€â”€ Prometheus (ë©”íŠ¸ë¦­)
   â”œâ”€â”€ HDFS (ë¶„ì„ ê²°ê³¼)
   â””â”€â”€ PostgreSQL (ì§‘ê³„ ë°ì´í„°)
   â”‚
   â–¼
6. ì‹œê°í™” (Grafana)
   â”‚
   â€¢ ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
   â€¢ ì•Œë¦¼ ì„¤ì •
```

---

## ğŸ–¥ï¸ PCë³„ ì—­í•  ë° êµ¬ì„±

### ì—­í•  ë¶„ë°°

| PC | ì—­í•  | ì£¼ìš” ì»´í¬ë„ŒíŠ¸ | ê¶Œì¥ ì‚¬ì–‘ |
|-----|------|-------------|----------|
| **ë…¸íŠ¸ë¶** | Master + Generator | K8s Control Plane, Java Backend, Kafka, Spark Driver, Monitoring | 8GB+ RAM, 4+ Core |
| **ë¦¬ëˆ…ìŠ¤ A** | Worker Node 1 | K8s Worker, HDFS DataNode, Spark Executor | 4GB+ RAM, 2+ Core |
| **ë¦¬ëˆ…ìŠ¤ B** | Worker Node 2 | K8s Worker, HDFS DataNode, Spark Executor | 4GB+ RAM, 2+ Core |

### ë„¤íŠ¸ì›Œí¬ êµ¬ì„±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Network Topology                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         192.168.x.0/24 (ì˜ˆì‹œ)
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚             â”‚
    â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚Master â”‚    â”‚Worker1â”‚    â”‚Worker2â”‚
â”‚  .10  â”‚    â”‚  .11  â”‚    â”‚  .12  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜

í•„ìš” í¬íŠ¸:
â€¢ 6443  : Kubernetes API
â€¢ 9092  : Kafka
â€¢ 9870  : HDFS NameNode Web UI
â€¢ 8080  : Spark Master Web UI
â€¢ 3000  : Grafana
â€¢ 8081  : Java Backend API
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
distributed-log-pipeline/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml              # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
â”œâ”€â”€ .env.example                    # í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿
â”‚
â”œâ”€â”€ docs/                           # ë¬¸ì„œ
â”‚   â”œâ”€â”€ SETUP_MASTER.md            # ë§ˆìŠ¤í„° ë…¸ë“œ ì„¤ì • ê°€ì´ë“œ
â”‚   â”œâ”€â”€ SETUP_WORKER.md            # ì›Œì»¤ ë…¸ë“œ ì„¤ì • ê°€ì´ë“œ
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md         # ë¬¸ì œ í•´ê²° ê°€ì´ë“œ
â”‚   â””â”€â”€ ARCHITECTURE.md            # ìƒì„¸ ì•„í‚¤í…ì²˜ ë¬¸ì„œ
â”‚
â”œâ”€â”€ generator/                      # ë°ì´í„° ìƒì„±ê¸° (Python)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                # FastAPI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ scheduler.py           # ë°°ì¹˜ ìŠ¤ì¼€ì¤„ëŸ¬
â”‚   â”‚   â”œâ”€â”€ generators/
â”‚   â”‚   â”‚   â”œâ”€â”€ log_generator.py   # ë¡œê·¸ ë°ì´í„° ìƒì„±
â”‚   â”‚   â”‚   â””â”€â”€ event_generator.py # ì´ë²¤íŠ¸ ë°ì´í„° ìƒì„±
â”‚   â”‚   â””â”€â”€ config.py              # ì„¤ì •
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ backend/                        # ìˆ˜ì§‘ ì„œë²„ (Java Spring Boot)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ pom.xml
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ main/
â”‚   â”‚       â”œâ”€â”€ java/
â”‚   â”‚       â”‚   â””â”€â”€ com/pipeline/
â”‚   â”‚       â”‚       â”œâ”€â”€ PipelineApplication.java
â”‚   â”‚       â”‚       â”œâ”€â”€ controller/
â”‚   â”‚       â”‚       â”‚   â””â”€â”€ CollectorController.java
â”‚   â”‚       â”‚       â”œâ”€â”€ service/
â”‚   â”‚       â”‚       â”‚   â””â”€â”€ KafkaProducerService.java
â”‚   â”‚       â”‚       â”œâ”€â”€ model/
â”‚   â”‚       â”‚       â”‚   â”œâ”€â”€ LogEvent.java
â”‚   â”‚       â”‚       â”‚   â””â”€â”€ ActivityEvent.java
â”‚   â”‚       â”‚       â””â”€â”€ config/
â”‚   â”‚       â”‚           â””â”€â”€ KafkaConfig.java
â”‚   â”‚       â””â”€â”€ resources/
â”‚   â”‚           â””â”€â”€ application.yml
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ spark-jobs/                     # Spark ì‘ì—… (PySpark)
â”‚   â”œâ”€â”€ streaming/
â”‚   â”‚   â”œâ”€â”€ realtime_aggregator.py # ì‹¤ì‹œê°„ ì§‘ê³„
â”‚   â”‚   â””â”€â”€ anomaly_detector.py    # ì´ìƒ íƒì§€
â”‚   â”œâ”€â”€ batch/
â”‚   â”‚   â”œâ”€â”€ daily_report.py        # ì¼ë³„ ë¦¬í¬íŠ¸
â”‚   â”‚   â””â”€â”€ weekly_analysis.py     # ì£¼ê°„ ë¶„ì„
â”‚   â””â”€â”€ common/
â”‚       â””â”€â”€ spark_utils.py         # ê³µí†µ ìœ í‹¸
â”‚
â”œâ”€â”€ airflow/                        # ì›Œí¬í”Œë¡œìš° ìŠ¤ì¼€ì¤„ë§
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ daily_pipeline.py
â”‚   â”‚   â””â”€â”€ weekly_pipeline.py
â”‚   â””â”€â”€ plugins/
â”‚
â”œâ”€â”€ kubernetes/                     # K8s ë§¤ë‹ˆí˜ìŠ¤íŠ¸
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ master/                    # ë§ˆìŠ¤í„° ë…¸ë“œìš©
â”‚   â”‚   â”œâ”€â”€ kafka/
â”‚   â”‚   â”‚   â”œâ”€â”€ zookeeper.yaml
â”‚   â”‚   â”‚   â””â”€â”€ kafka.yaml
â”‚   â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”‚   â””â”€â”€ spark-master.yaml
â”‚   â”‚   â””â”€â”€ monitoring/
â”‚   â”‚       â”œâ”€â”€ prometheus.yaml
â”‚   â”‚       â””â”€â”€ grafana.yaml
â”‚   â”œâ”€â”€ worker/                    # ì›Œì»¤ ë…¸ë“œìš©
â”‚   â”‚   â”œâ”€â”€ hdfs/
â”‚   â”‚   â”‚   â””â”€â”€ datanode.yaml
â”‚   â”‚   â””â”€â”€ spark/
â”‚   â”‚       â””â”€â”€ spark-worker.yaml
â”‚   â””â”€â”€ common/                    # ê³µí†µ
â”‚       â”œâ”€â”€ configmaps.yaml
â”‚       â””â”€â”€ secrets.yaml
â”‚
â”œâ”€â”€ hadoop/                         # Hadoop ì„¤ì •
â”‚   â”œâ”€â”€ core-site.xml
â”‚   â”œâ”€â”€ hdfs-site.xml
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ start-namenode.sh
â”‚       â””â”€â”€ start-datanode.sh
â”‚
â”œâ”€â”€ monitoring/                     # ëª¨ë‹ˆí„°ë§ ì„¤ì •
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â””â”€â”€ dashboards/
â”‚   â”‚       â”œâ”€â”€ overview.json      # ì „ì²´ í˜„í™© ëŒ€ì‹œë³´ë“œ
â”‚   â”‚       â”œâ”€â”€ kafka.json         # Kafka ëª¨ë‹ˆí„°ë§
â”‚   â”‚       â””â”€â”€ spark.json         # Spark ëª¨ë‹ˆí„°ë§
â”‚   â””â”€â”€ prometheus/
â”‚       â””â”€â”€ prometheus.yml
â”‚
â””â”€â”€ scripts/                        # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ setup-master.sh            # ë§ˆìŠ¤í„° ì´ˆê¸° ì„¤ì •
    â”œâ”€â”€ setup-worker.sh            # ì›Œì»¤ ì´ˆê¸° ì„¤ì •
    â”œâ”€â”€ deploy-all.sh              # ì „ì²´ ë°°í¬
    â””â”€â”€ cleanup.sh                 # ì •ë¦¬
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

**ëª¨ë“  PC ê³µí†µ:**
```bash
# Docker ì„¤ì¹˜
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# kubectl ì„¤ì¹˜
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
```

### Step 1: í”„ë¡œì íŠ¸ í´ë¡  (ëª¨ë“  PC)

```bash
git clone https://github.com/your-repo/distributed-log-pipeline.git
cd distributed-log-pipeline
cp .env.example .env
# .env íŒŒì¼ì—ì„œ ê° PCì˜ IP ì£¼ì†Œ ì„¤ì •
```

### Step 2: Master ë…¸ë“œ ì„¤ì • (ë…¸íŠ¸ë¶)

```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export NODE_ROLE=master
export MASTER_IP=192.168.x.10  # ì‹¤ì œ IPë¡œ ë³€ê²½

# Kubernetes í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™”
./scripts/setup-master.sh

# ë§ˆìŠ¤í„° ì»´í¬ë„ŒíŠ¸ ë°°í¬
kubectl apply -f kubernetes/master/

# Java Backend ì‹¤í–‰
cd backend
./mvnw spring-boot:run

# ë°ì´í„° ìƒì„±ê¸° ì‹¤í–‰ (ë³„ë„ í„°ë¯¸ë„)
cd generator
pip install -r requirements.txt
python -m app.main
```

### Step 3: Worker ë…¸ë“œ ì„¤ì • (ë¦¬ëˆ…ìŠ¤ A, B)

```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export NODE_ROLE=worker
export MASTER_IP=192.168.x.10  # ë§ˆìŠ¤í„° IP

# í´ëŸ¬ìŠ¤í„° ì¡°ì¸
./scripts/setup-worker.sh

# ì›Œì»¤ ì»´í¬ë„ŒíŠ¸ ë°°í¬
kubectl apply -f kubernetes/worker/
```

### Step 4: ë™ì‘ í™•ì¸

```bash
# í´ëŸ¬ìŠ¤í„° ìƒíƒœ í™•ì¸
kubectl get nodes
kubectl get pods -A

# HDFS ìƒíƒœ í™•ì¸
hdfs dfsadmin -report

# Kafka í† í”½ í™•ì¸
kafka-topics.sh --list --bootstrap-server localhost:9092

# Grafana ì ‘ì†
# ë¸Œë¼ìš°ì €ì—ì„œ http://<MASTER_IP>:3000 ì ‘ì†
# ê¸°ë³¸ ê³„ì •: admin / admin
```

---

## ğŸ“Š ìƒì„± ë°ì´í„° í˜•ì‹

### ì‹œìŠ¤í…œ ë¡œê·¸

```json
{
  "timestamp": "2024-01-15T10:30:00.123Z",
  "level": "INFO",
  "service": "api-gateway",
  "host": "worker-1",
  "message": "Request processed successfully",
  "metadata": {
    "request_id": "uuid-1234",
    "response_time_ms": 45,
    "status_code": 200,
    "endpoint": "/api/users",
    "method": "GET"
  }
}
```

### ì‚¬ìš©ì í™œë™ ì´ë²¤íŠ¸

```json
{
  "event_id": "evt-uuid-5678",
  "timestamp": "2024-01-15T10:30:05.456Z",
  "user_id": "user_12345",
  "session_id": "sess_abcde",
  "event_type": "CLICK",
  "event_data": {
    "page": "/products/123",
    "element": "add_to_cart_button",
    "position": {"x": 450, "y": 320}
  },
  "device": {
    "type": "mobile",
    "os": "iOS",
    "browser": "Safari"
  }
}
```

---

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### ì œê³µë˜ëŠ” ëŒ€ì‹œë³´ë“œ

| ëŒ€ì‹œë³´ë“œ | ì„¤ëª… | ì£¼ìš” ë©”íŠ¸ë¦­ |
|---------|------|------------|
| **Overview** | ì‹œìŠ¤í…œ ì „ì²´ í˜„í™© | ë…¸ë“œ ìƒíƒœ, ì²˜ë¦¬ëŸ‰, ì—ëŸ¬ìœ¨ |
| **Kafka** | ë©”ì‹œì§€ í ëª¨ë‹ˆí„°ë§ | í† í”½ë³„ ì²˜ë¦¬ëŸ‰, ì§€ì—°ì‹œê°„, ì»¨ìŠˆë¨¸ ë™ |
| **Spark** | ì²˜ë¦¬ ì‘ì—… ëª¨ë‹ˆí„°ë§ | ì‘ì—… ìƒíƒœ, ì²˜ë¦¬ ì‹œê°„, ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ |
| **HDFS** | ì €ì¥ì†Œ ëª¨ë‹ˆí„°ë§ | ìš©ëŸ‰, ë³µì œ ìƒíƒœ, ë…¸ë“œ ìƒíƒœ |

### ì•Œë¦¼ ì„¤ì •

```yaml
# ê¸°ë³¸ ì œê³µ ì•Œë¦¼ ê·œì¹™
alerts:
  - name: HighErrorRate
    condition: error_rate > 5%
    duration: 5m
    
  - name: KafkaLag
    condition: consumer_lag > 10000
    duration: 10m
    
  - name: SparkJobFailed
    condition: job_status == "FAILED"
```

---

## ğŸ”§ ì£¼ìš” ì„¤ì •

### ë°°ì¹˜ ìŠ¤ì¼€ì¤„ ì„¤ì • (generator/app/config.py)

```python
BATCH_CONFIG = {
    "log_interval_seconds": 5,      # ë¡œê·¸ ìƒì„± ì£¼ê¸°
    "event_interval_seconds": 10,   # ì´ë²¤íŠ¸ ìƒì„± ì£¼ê¸°
    "batch_size": 100,              # ë°°ì¹˜ë‹¹ ë°ì´í„° ìˆ˜
    "target_backend_url": "http://master:8081/api/collect"
}
```

### Kafka í† í”½ ì„¤ì •

| í† í”½ | íŒŒí‹°ì…˜ | ë³µì œ ê³„ìˆ˜ | ë³´ì¡´ ê¸°ê°„ |
|------|--------|----------|----------|
| logs.raw | 3 | 2 | 7ì¼ |
| events.activity | 3 | 2 | 7ì¼ |
| alerts.realtime | 1 | 2 | 1ì¼ |

---

## ğŸ› ï¸ ê°œë°œ ê°€ì´ë“œ

### ë¡œì»¬ í…ŒìŠ¤íŠ¸ (Docker Compose)

```bash
# ì „ì²´ ìŠ¤íƒ ë¡œì»¬ ì‹¤í–‰ (ë‹¨ì¼ PC í…ŒìŠ¤íŠ¸ìš©)
docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f

# ì¢…ë£Œ
docker-compose down -v
```

### ìƒˆë¡œìš´ Spark Job ì¶”ê°€

```python
# spark-jobs/batch/my_new_job.py

from pyspark.sql import SparkSession
from common.spark_utils import get_spark_session, read_from_hdfs

def main():
    spark = get_spark_session("MyNewJob")
    
    # HDFSì—ì„œ ë°ì´í„° ì½ê¸°
    df = read_from_hdfs(spark, "/data/logs/2024/01/15")
    
    # ì²˜ë¦¬ ë¡œì§
    result = df.groupBy("level").count()
    
    # ê²°ê³¼ ì €ì¥
    result.write.mode("overwrite").parquet("/data/results/my_job")

if __name__ == "__main__":
    main()
```

---

## ğŸ“š í•™ìŠµ ë¡œë“œë§µ

### Week 1-2: í™˜ê²½ êµ¬ì¶•
- [ ] 3ëŒ€ PC ë„¤íŠ¸ì›Œí¬ êµ¬ì„±
- [ ] Docker, kubectl ì„¤ì¹˜
- [ ] Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì¶•
- [ ] ê¸°ë³¸ í†µì‹  í…ŒìŠ¤íŠ¸

### Week 3: ë°ì´í„° íŒŒì´í”„ë¼ì¸ ê¸°ì´ˆ
- [ ] Kafka ì„¤ì¹˜ ë° í† í”½ ìƒì„±
- [ ] Java Backend ê°œë°œ
- [ ] Python Generator ê°œë°œ
- [ ] ê¸°ë³¸ ë°ì´í„° í”Œë¡œìš° í™•ì¸

### Week 4: HDFS ì—°ë™
- [ ] HDFS í´ëŸ¬ìŠ¤í„° êµ¬ì„±
- [ ] Kafka â†’ HDFS ì—°ë™
- [ ] ë°ì´í„° ì ì¬ í™•ì¸

### Week 5: Spark ì²˜ë¦¬
- [ ] Spark Streaming ì‘ì—… ê°œë°œ
- [ ] Batch ì‘ì—… ê°œë°œ
- [ ] Airflow ìŠ¤ì¼€ì¤„ë§

### Week 6: ëª¨ë‹ˆí„°ë§
- [ ] Prometheus + Grafana êµ¬ì„±
- [ ] ëŒ€ì‹œë³´ë“œ êµ¬ì„±
- [ ] ì•Œë¦¼ ì„¤ì •
- [ ] ì „ì²´ í†µí•© í…ŒìŠ¤íŠ¸

---

## â“ FAQ

### Q: ë‹¨ì¼ PCì—ì„œë„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆë‚˜ìš”?
A: ë„¤, `docker-compose up`ìœ¼ë¡œ ë¡œì»¬ì—ì„œ ì „ì²´ ìŠ¤íƒì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Q: ìµœì†Œ ì‚¬ì–‘ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
A: Master 8GB RAM, Worker ê° 4GB RAMì„ ê¶Œì¥í•©ë‹ˆë‹¤. ë” ë‚®ì€ ì‚¬ì–‘ì—ì„œë„ ë™ì‘í•˜ì§€ë§Œ ì„±ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Q: Windowsì—ì„œë„ ê°€ëŠ¥í•œê°€ìš”?
A: WSL2 + Docker Desktop í™˜ê²½ì—ì„œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¨, ë„¤íŠ¸ì›Œí¬ ì„¤ì •ì´ ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.