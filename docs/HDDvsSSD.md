1. HDD의 본질: "헤드는 움직이는 게 고통이다"
   HDD는 레코드판처럼 바늘(헤드)이 돌아가는 원판 위를 움직이며 데이터를 읽습니다.

순차 읽기 (Sequential I/O): 헤드가 가만히 있고 판이 돌면서 데이터를 쭉 읽는 방식. 매우 빠릅니다.

무작위 읽기 (Random I/O): 이 주소 갔다가 저 주소 갔다가 헤드가 계속 점프하는 방식. 이때 엄청난 지연(Latency)이 발생합니다.

2. PostgreSQL이 HDD에서 고통받는 이유 (포인터 점프)
   준형 님이 말씀하신 **"포인터 점프"**가 바로 무작위 읽기를 유발합니다.

PostgreSQL에서 인덱스로 데이터를 찾으면: 인덱스 페이지 확인 -> 포인터 추출 -> 실제 데이터 블록으로 점프 과정이 일어납니다.

데이터가 10억 건이면 이 '점프'가 수억 번 일어나는데, HDD 헤드가 그 속도를 못 따라가서 시스템이 멈추는 겁니다.

3. 하둡/스파크가 HDD에서 강한 이유 (Full Scan & Sequential)
   하둡/스파크는 **"어차피 점프하면 느리니까, 그냥 처음부터 끝까지 무식하게 쭉 다 읽자!"**는 전략입니다.

HDD 입장에서는 헤드를 고정하고 판을 돌리며 데이터를 쏟아붓는 방식이라 최대 대역폭을 다 쓸 수 있습니다.

"찾는 것(Index)"보다 "다 읽는 것(Scan)"이 더 빠른 역설적인 상황이 대용량 HDD 환경에서 발생합니다.

4. 파케이(Parquet)와 열 지향(Columnar)이 뭐야?
   이 '무식하게 다 읽는 방식'을 더 똑똑하게 만든 게 열 지향(Columnar) 저장입니다.

행 지향 (Row-oriented, PostgreSQL): 데이터를 이름, 나이, 로그내용 / 이름, 나이, 로그내용 순으로 저장합니다. "나이의 평균"을 구하고 싶어도 필요 없는 "이름"과 "로그내용"까지 다 읽어야 합니다.

열 지향 (Columnar, Parquet): 데이터를 이름, 이름, 이름... / 나이, 나이, 나이... / 로그내용, 로그내용... 처럼 컬럼별로 모아서 저장합니다.

이게 왜 로그 분석(통계)에서 무서운 성능을 낼까요?

필요한 것만 읽기: "에러 로그 개수"만 세고 싶다면, 디스크에서 로그 레벨 컬럼이 저장된 구역만 순차적으로 쭉 읽으면 됩니다. 나머지 300GB의 데이터는 건드리지도 않습니다.

압축률: 같은 컬럼끼리는 데이터 형식이 비슷해서(예: 'INFO', 'ERROR' 반복) 압축이 미친 듯이 잘 됩니다. 디스크 용량도 아끼고, 읽어올 양도 줄어드니 속도가 또 빨라집니다.