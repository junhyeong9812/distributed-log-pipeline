services:
  # ================================
  # Kafka (KRaft 모드)
  # ================================
  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.55.114:9092
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@localhost:9093
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - pipeline-network

  # ================================
  # Java Backend
  # ================================
  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: backend
    ports:
      - "8081:8081"
    environment:
      - KAFKA_SERVERS=kafka:9092
    depends_on:
      - kafka
    networks:
      - pipeline-network

  # ================================
  # Python Generator
  # ================================
  generator:
    build:
      context: ../generator
      dockerfile: Dockerfile
    container_name: generator
    ports:
      - "8000:8000"
    environment:
      - GENERATOR_BACKEND_URL=http://backend:8081
      - GENERATOR_LOG_INTERVAL_SECONDS=5
      - GENERATOR_EVENT_INTERVAL_SECONDS=10
      - GENERATOR_BATCH_SIZE=100
    depends_on:
      - backend
    networks:
      - pipeline-network

  # ================================
  # Kafka UI
  # ================================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on:
      - kafka
    networks:
      - pipeline-network

  # ================================
  # HDFS NameNode
  # ================================
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    ports:
      - "9870:9870"
      - "9000:9000"
    environment:
      - CLUSTER_NAME=distributed-log-pipeline
      - CORE_CONF_fs_defaultFS=hdfs://192.168.55.114:9000
      - CORE_CONF_hadoop_http_staticuser_user=root
      - HDFS_CONF_dfs_webhdfs_enabled=true
      - HDFS_CONF_dfs_permissions_enabled=false
      - HDFS_CONF_dfs_replication=2
    volumes:
      - namenode_data:/hadoop/dfs/name
    networks:
      - pipeline-network

  # ================================
  # Spark Master
  # ================================
  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8082:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - ../spark-jobs:/opt/spark-jobs
    networks:
      - pipeline-network

  # ================================
  # Airflow
  # ================================
  airflow:
    image: apache/airflow:2.7.0-python3.10
    container_name: airflow
    user: root
    ports:
      - "8084:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__CORE__FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=mysecretkey123
    volumes:
      - ../airflow/dags:/opt/airflow/dags
      - ../spark-jobs:/opt/spark-jobs
      - /var/run/docker.sock:/var/run/docker.sock
    command: bash -c "airflow db init && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true && (airflow webserver &) && airflow scheduler"
    networks:
      - pipeline-network

  # ================================
  # Prometheus
  # ================================
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ../monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - pipeline-network

  # ================================
  # Grafana
  # ================================
  grafana:
    image: grafana/grafana:10.1.0
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ../monitoring/grafana/provisioning:/etc/grafana/provisioning
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - pipeline-network

volumes:
  kafka_data:
  namenode_data:
  prometheus_data:
  grafana_data:

networks:
  pipeline-network:
    driver: bridge
